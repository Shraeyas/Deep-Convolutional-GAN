{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5VypR2zpywc",
    "outputId": "d26999b5-e615-4961-f49a-fc8cf667e1bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 17 10:56:28 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M4000        On   | 00000000:00:05.0 Off |                  N/A |\n",
      "| 46%   26C    P8    11W / 120W |      1MiB /  8126MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:00:05.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oZOR8ZYaZHEf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 21.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.19.4)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
      "\u001b[K     |████████████████████████████████| 890 kB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.4.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 27.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 31.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, pandas, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.28.5 kiwisolver-1.3.2 matplotlib-3.5.1 pandas-1.3.5 pillow-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib pandas\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from CustomLayers import CustomConv2D, CustomConvTranspose2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Zu-tjSu7ZHHK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.2.0.tar.gz (13 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.4.2-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.26.0)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.2.0-py3-none-any.whl size=14262 sha256=5d9e680a780d6934dcea52bc7d9244be2c360e3cad578561991b9780f6e17bd1\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/3c/51/52c46deda5cd1d59c6ce3d441ea5f3d155495dc294c4535a25\n",
      "Successfully built gdown\n",
      "Installing collected packages: soupsieve, PySocks, filelock, beautifulsoup4, gdown\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.10.0 filelock-3.4.2 gdown-4.2.0 soupsieve-2.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "import gdown\n",
    "try:\n",
    "    os.makedirs(\"celeba_gan\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n",
    "path = \"celeba_gan/data.zip\"\n",
    "gdown.download(url, path, quiet = True)\n",
    "\n",
    "with ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n",
    "    zipobj.extractall(\"celeba_gan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNtlgqHdZHNj",
    "outputId": "4fc5e1ca-afa6-41f9-eede-2c7f64c258ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 11:01:22.174174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:22.187526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:22.188499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:22.190739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:22.191784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:22.192692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:23.461109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:23.461721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:23.462337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 11:01:23.462990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7286 MB memory:  -> device: 0, name: Quadro M4000, pci bus id: 0000:00:05.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"celeba_gan/img_align_celeba\"\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(directory = data_directory,\n",
    "                                                           label_mode = None,\n",
    "                                                           image_size = (64, 64),\n",
    "                                                           batch_size = 32,\n",
    "                                                           shuffle = True).map(lambda x : x/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2nmPLU_Viaj"
   },
   "source": [
    "### **Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VC8KvBLZVZeH",
    "outputId": "e83c5ce2-3b72-4454-9b7d-994e0b31d360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 65536)             8454144   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "custom_conv_transpose2d (Cus (None, 16, 16, 512)       13109760  \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       3277056   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 3)         19203     \n",
      "=================================================================\n",
      "Total params: 24,860,163\n",
      "Trainable params: 24,859,139\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "noise_dim = 128\n",
    "input = layers.Input(shape = (noise_dim,))\n",
    "dense = layers.Dense(8 * 8 * 1024)(input)\n",
    "conv = layers.Reshape((8, 8, 1024))(dense)\n",
    "conv_t = CustomConvTranspose2D(512, kernel_size = 5, strides = 2, padding = \"same\")(conv)\n",
    "conv_t = layers.Conv2DTranspose(256, kernel_size = 5, strides = 2, padding = \"same\")(conv_t)\n",
    "# conv_t = layers.Conv2DTranspose(128, kernel_size = 5, strides = 2, padding = \"same\")(conv_t)\n",
    "output = layers.Conv2DTranspose(3, kernel_size = 5, strides = 2, padding = \"same\", activation = \"sigmoid\")(conv_t)\n",
    "\n",
    "generator = keras.Model(inputs = input, outputs = output)\n",
    "print(generator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDIwsPl5Va8d"
   },
   "source": [
    "### **Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFeqZlpnZHSa",
    "outputId": "c1a25451-4f58-4e29-d931-6663b051ac2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "custom_conv2d (CustomConv2D) (None, 32, 32, 64)        3392      \n",
      "_________________________________________________________________\n",
      "custom_conv2d_1 (CustomConv2 (None, 16, 16, 128)       131712    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 167,873\n",
      "Trainable params: 167,489\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input = keras.Input(shape = (64, 64, 3))\n",
    "conv = CustomConv2D(64, kernel_size = 4, strides = 2, padding = \"same\")(input)\n",
    "conv = CustomConv2D(128, kernel_size = 4, strides = 2, padding = \"same\")(conv)\n",
    "# conv = CustomConv2D(256, kernel_size = 4, strides = 2, padding = \"same\")(conv)\n",
    "# conv = CustomConv2D(512, kernel_size = 4, strides = 2, padding = \"same\")(conv)\n",
    "output = layers.Flatten()(conv)\n",
    "output = layers.Dropout(0.2)(output)\n",
    "output = layers.Dense(1, activation = \"sigmoid\")(output)\n",
    "\n",
    "discriminator = keras.Model(inputs = input, outputs = output)\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgBIYlVbjkmr"
   },
   "source": [
    "### **Optimisers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5BC70fInjfra"
   },
   "outputs": [],
   "source": [
    "opt_gen = keras.optimizers.Adam(2e-4)\n",
    "opt_disc = keras.optimizers.Adam(2e-4)\n",
    "loss_fn = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuLkVXXrmJmb"
   },
   "source": [
    "### **Train Discriminator and Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zktmHgpdjfth"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training from Scratch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6332 [00:00<?, ?it/s]2022-01-17 11:01:34.889535: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "result_folder = str(time.time())\n",
    "try:\n",
    "    os.mkdir(\"models\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    generator = tf.keras.models.load_model(os.path.join(\"models\", \"generator\"))\n",
    "    discriminator = tf.keras.models.load_model(os.path.join(\"models\", \"discriminator\"))\n",
    "    print(\"Loading Models from Disk!\")\n",
    "except:\n",
    "    print(\"Starting Training from Scratch!\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    for idx, real in enumerate(tqdm(dataset)):\n",
    "        batch_size = real.shape[0]\n",
    "        random_noise_vectors = tf.random.normal(shape = (batch_size, noise_dim))\n",
    "\n",
    "        with tf.GradientTape(persistent = True) as tape:\n",
    "            fake = generator(random_noise_vectors)\n",
    "            output_disc_fake = discriminator(fake)\n",
    "            output_disc_real = discriminator(real)\n",
    "            \n",
    "            loss_disc_real = loss_fn(tf.ones(batch_size, 1), output_disc_real)\n",
    "            loss_disc_fake = loss_fn(tf.zeros(batch_size, 1), output_disc_fake)\n",
    "            loss_disc = loss_disc_real + loss_disc_fake            \n",
    "            loss_gen = loss_fn(tf.ones(batch_size, 1), output_disc_fake)\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            img = fake[0].numpy().astype('float32')\n",
    "            result_name = f\"{epoch}_{idx}_.png\"\n",
    "            result_path = \"results\"\n",
    "            try:\n",
    "                os.mkdir(result_path)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                os.mkdir(os.path.join(result_path, result_folder))\n",
    "            except:\n",
    "                pass\n",
    "            result_path = os.path.join(result_path, result_folder)\n",
    "            result_path = os.path.join(result_path, result_name)\n",
    "            plt.imsave(result_path, img)\n",
    "            generator.save(os.path.join(\"models\", \"generator\"))\n",
    "            discriminator.save(os.path.join(\"models\", \"discriminator\"))\n",
    "            clear_output()\n",
    "\n",
    "        grads = tape.gradient(loss_disc, discriminator.trainable_weights)\n",
    "        opt_disc.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "        grads = tape.gradient(loss_gen, generator.trainable_weights)\n",
    "        opt_gen.apply_gradients(zip(grads, generator.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
