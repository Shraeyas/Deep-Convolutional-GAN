{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5VypR2zpywc",
    "outputId": "d26999b5-e615-4961-f49a-fc8cf667e1bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 17 08:53:21 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M4000        On   | 00000000:00:05.0 Off |                  N/A |\n",
      "| 56%   61C    P0    45W / 120W |   7730MiB /  8126MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "oZOR8ZYaZHEf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gdown\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from CustomLayers import CustomConv2D, CustomConvTranspose2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Zu-tjSu7ZHHK"
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#   os.makedirs(\"celeba_gan\")\n",
    "# except:\n",
    "#   pass\n",
    "\n",
    "# url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n",
    "# path = \"celeba_gan/data.zip\"\n",
    "# gdown.download(url, path, quiet = True)\n",
    "\n",
    "# with ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n",
    "#   zipobj.extractall(\"celeba_gan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNtlgqHdZHNj",
    "outputId": "4fc5e1ca-afa6-41f9-eede-2c7f64c258ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"celeba_gan/img_align_celeba\"\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(directory = data_directory,\n",
    "                                                           label_mode = None,\n",
    "                                                           image_size = (128, 128),\n",
    "                                                           batch_size = 64,\n",
    "                                                           shuffle = True).map(lambda x : x/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2nmPLU_Viaj"
   },
   "source": [
    "### **Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VC8KvBLZVZeH",
    "outputId": "e83c5ce2-3b72-4454-9b7d-994e0b31d360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16384)             2113536   \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "custom_conv_transpose2d_4 (C (None, 8, 8, 512)         13109760  \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_36 (Conv2DT (None, 16, 16, 256)       3277056   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_37 (Conv2DT (None, 32, 32, 128)       819328    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_38 (Conv2DT (None, 64, 64, 64)        204864    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_39 (Conv2DT (None, 128, 128, 3)       4803      \n",
      "=================================================================\n",
      "Total params: 19,529,347\n",
      "Trainable params: 19,528,323\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "noise_dim = 128\n",
    "input = layers.Input(shape = (noise_dim,))\n",
    "dense = layers.Dense(4 * 4 * 1024)(input)\n",
    "conv = layers.Reshape((4, 4, 1024))(dense)\n",
    "conv_t = CustomConvTranspose2D(512, kernel_size = 5, strides = 2, padding = \"same\")(conv)\n",
    "\n",
    "conv_t = layers.Conv2DTranspose(256, kernel_size = 5, strides = 2, padding = \"same\")(conv_t)\n",
    "conv_t = layers.Conv2DTranspose(128, kernel_size = 5, strides = 2, padding = \"same\")(conv_t)\n",
    "              \n",
    "conv_t = layers.Conv2DTranspose(64, kernel_size = 5, strides = 2, padding = \"same\")(conv_t)\n",
    "output = layers.Conv2DTranspose(3, kernel_size = 5, strides = 2, padding = \"same\", activation = \"sigmoid\")(conv_t)\n",
    "\n",
    "generator = keras.Model(inputs = input, outputs = output)\n",
    "print(generator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDIwsPl5Va8d"
   },
   "source": [
    "### **Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFeqZlpnZHSa",
    "outputId": "c1a25451-4f58-4e29-d931-6663b051ac2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "custom_conv2d_7 (CustomConv2 (None, 64, 64, 64)        3392      \n",
      "_________________________________________________________________\n",
      "custom_conv2d_8 (CustomConv2 (None, 32, 32, 128)       131712    \n",
      "_________________________________________________________________\n",
      "custom_conv2d_9 (CustomConv2 (None, 16, 16, 256)       525568    \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65537     \n",
      "=================================================================\n",
      "Total params: 726,209\n",
      "Trainable params: 725,313\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input = keras.Input(shape = (128, 128, 3))\n",
    "conv = CustomConv2D(64, kernel_size = 4, strides = 2, padding = \"same\")(input)\n",
    "conv = CustomConv2D(128, kernel_size = 4, strides = 2, padding = \"same\")(conv)\n",
    "conv = CustomConv2D(256, kernel_size = 4, strides = 2, padding = \"same\")(conv)\n",
    "output = layers.Flatten()(conv)\n",
    "output = layers.Dropout(0.2)(output)\n",
    "output = layers.Dense(1, activation = \"sigmoid\")(output)\n",
    "\n",
    "discriminator = keras.Model(inputs = input, outputs = output)\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgBIYlVbjkmr"
   },
   "source": [
    "### **Optimisers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "5BC70fInjfra"
   },
   "outputs": [],
   "source": [
    "opt_gen = keras.optimizers.Adam(1e-4)\n",
    "opt_disc = keras.optimizers.Adam(1e-4)\n",
    "loss_fn = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuLkVXXrmJmb"
   },
   "source": [
    "### **Train Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zktmHgpdjfth"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 600/3166 [07:58<32:28,  1.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as leaky_re_lu_30_layer_call_fn, leaky_re_lu_30_layer_call_and_return_conditional_losses, leaky_re_lu_30_layer_call_fn, leaky_re_lu_30_layer_call_and_return_conditional_losses, leaky_re_lu_30_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/generator/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/generator/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "try:\n",
    "    os.mkdir(\"models\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    generator = tf.keras.models.load_model(os.path.join(\"models\", \"generator\"))\n",
    "    discriminator = tf.keras.models.load_model(os.path.join(\"models\", \"discriminator\"))\n",
    "    print(\"Loading Models from Disk!\")\n",
    "except:\n",
    "    print(\"Starting Training from Scratch!\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    for idx, real in enumerate(tqdm(dataset)):\n",
    "        batch_size = real.shape[0]\n",
    "        with tf.GradientTape(persistent = True) as tape:\n",
    "            fake = generator(random_latent_vectors)\n",
    "            output_disc_fake = discriminator(fake)\n",
    "            output_disc_real = discriminator(real)\n",
    "            \n",
    "            loss_disc_real = loss_fn(tf.ones(batch_size, 1), output_disc_real)\n",
    "            loss_disc_fake = loss_fn(tf.zeros(batch_size, 1), output_disc_fake)\n",
    "            loss_disc = loss_disc_real + loss_disc_fake            \n",
    "            loss_gen = loss_fn(tf.ones(batch_size, 1), output_disc_fake)\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            img = fake[0].numpy().astype('float32')\n",
    "            result_name = f\"{epoch}_{idx}_.png\"\n",
    "            result_path = \"results\"\n",
    "            try:\n",
    "                os.mkdir(result_path)\n",
    "            except:\n",
    "                pass\n",
    "            result_path = os.path.join(result_path, result_name)\n",
    "            plt.imsave(result_path, img)\n",
    "            generator.save(os.path.join(\"models\", \"generator\"))\n",
    "            discriminator.save(os.path.join(\"models\", \"discriminator\"))\n",
    "            clear_output()\n",
    "\n",
    "        grads = tape.gradient(loss_disc, discriminator.trainable_weights)\n",
    "        opt_disc.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "        grads = tape.gradient(loss_gen, generator.trainable_weights)\n",
    "        opt_gen.apply_gradients(zip(grads, generator.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
